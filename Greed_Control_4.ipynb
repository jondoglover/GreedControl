{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOp2/A9P1+H4m5eI5W4WSrU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p82eCtzh-4YO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split as train_test_split\n",
        "import requests\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_aops_stats(date):\n",
        "    url = \"https://artofproblemsolving.com/m/greedcontrol/ajax.php\"\n",
        "    headers = {\n",
        "        \"Accept\": \"application/json, text/javascript, */*; q=0.01\",\n",
        "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
        "        \"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
        "        \"Priority\": \"u=1, i\",\n",
        "        \"Sec-Fetch-Dest\": \"empty\",\n",
        "        \"Sec-Fetch-Mode\": \"cors\",\n",
        "        \"Sec-Fetch-Site\": \"same-origin\",\n",
        "        \"X-Requested-With\": \"XMLHttpRequest\"\n",
        "    }\n",
        "    data = {\n",
        "        \"action\": \"stats\",\n",
        "        \"date\": date\n",
        "    }\n",
        "\n",
        "    session = requests.Session()\n",
        "    response = session.post(url, headers=headers, data=data)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        try:\n",
        "            return response.json().get(\"response\", {}).get(\"data\", {})\n",
        "        except json.JSONDecodeError:\n",
        "            return {\"error\": \"Failed to parse JSON response.\"}\n",
        "    else:\n",
        "        return {\"error\": f\"Request failed with status code {response.status_code}\"}"
      ],
      "metadata": {
        "id": "OypLHmDuLups"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dates = [f\"2025-02-{x}\" for x in [\"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\"]]\n",
        "m = []\n",
        "for date in dates:\n",
        "    # print(fetch_aops_stats(date), date)\n",
        "    l = [int(q[1]) for q in fetch_aops_stats(date)]\n",
        "    m.append([w/sum(l) for w in l])"
      ],
      "metadata": {
        "id": "LZG_7HAeqTE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "Y_train = []"
      ],
      "metadata": {
        "id": "t8POXz7Q6MdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in range(len(m[0])):\n",
        "  for i in range(len(m)-4):\n",
        "    X_train.append([m[i][col],m[i+1][col],m[i+2][col]])\n",
        "    Y_train.append(m[i+3][col])\n",
        "\n",
        "predict_data = [[m[-3][c],m[-2][c],m[-1][c]] for c in range(len(m[0]))]"
      ],
      "metadata": {
        "id": "s1RpKSTBTnqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Rwgc4xU1OwrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(Y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P02cPMcnqyy_",
        "outputId": "36a94990-7c3f-44c2-ae6f-81c76f5faf10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(16, activation='relu', input_shape=(3,)),\n",
        "    tf.keras.layers.Dense(8, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
      ],
      "metadata": {
        "id": "t5rrgfQQ_x6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4dfe4f4-6410-4646-c26a-bfd23eb6b1b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, epochs=20, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy2jZ-y2AYuq",
        "outputId": "bd350113-39c4-4a23-fb83-b1676ff12a33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.6683e-04 - mae: 0.0174\n",
            "Epoch 2/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.5142e-04 - mae: 0.0156 \n",
            "Epoch 3/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2591e-04 - mae: 0.0152 \n",
            "Epoch 4/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6943e-04 - mae: 0.0138 \n",
            "Epoch 5/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.3216e-04 - mae: 0.0150 \n",
            "Epoch 6/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2657e-04 - mae: 0.0139 \n",
            "Epoch 7/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.8514e-04 - mae: 0.0138 \n",
            "Epoch 8/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9557e-04 - mae: 0.0152 \n",
            "Epoch 9/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4314e-04 - mae: 0.0135 \n",
            "Epoch 10/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7175e-04 - mae: 0.0138 \n",
            "Epoch 11/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.3215e-04 - mae: 0.0152 \n",
            "Epoch 12/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7338e-04 - mae: 0.0137 \n",
            "Epoch 13/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.6381e-04 - mae: 0.0149\n",
            "Epoch 14/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2912e-04 - mae: 0.0130 \n",
            "Epoch 15/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7094e-04 - mae: 0.0141 \n",
            "Epoch 16/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.5046e-04 - mae: 0.0125 \n",
            "Epoch 17/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.6593e-04 - mae: 0.0143 \n",
            "Epoch 18/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.4495e-04 - mae: 0.0140\n",
            "Epoch 19/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0238e-04 - mae: 0.0131 \n",
            "Epoch 20/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.7446e-04 - mae: 0.0145\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f238bff0bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(suppress = True)\n",
        "xooks = model.predict(np.array(predict_data))\n",
        "xooks = np.array([x/sum(xooks) for x in xooks])\n",
        "for i in range(len(xooks)):\n",
        "  print((i+1)/xooks[i], i+1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_YSkOWLAeZs",
        "outputId": "27a30946-a68f-4451-e587-1a13ee39b1b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 10 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f23801a6480> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
            "[111.86703] 1\n",
            "[151.03467] 2\n",
            "[165.09018] 3\n",
            "[234.31174] 4\n",
            "[263.72235] 5\n",
            "[307.18048] 6\n",
            "[263.12848] 7\n",
            "[421.78983] 8\n",
            "[315.36417] 9\n",
            "[344.3032] 10\n",
            "[317.61395] 11\n",
            "[397.71625] 12\n",
            "[427.83984] 13\n",
            "[383.87485] 14\n",
            "[850.12646] 15\n",
            "[588.2674] 16\n",
            "[450.89423] 17\n",
            "[508.25464] 18\n",
            "[542.07654] 19\n",
            "[524.11743] 20\n",
            "[589.59814] 21\n",
            "[514.8645] 22\n",
            "[602.87067] 23\n",
            "[650.68146] 24\n",
            "[396.5012] 25\n",
            "[486.9] 26\n",
            "[671.30927] 27\n",
            "[790.8942] 28\n",
            "[653.36414] 29\n",
            "[643.63885] 30\n",
            "[744.33075] 31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "loss = model.evaluate(X_test, Y_test, verbose=1)\n",
        "print(loss)\n",
        "print(X_test[0], Y_test[0])\n",
        "r2 = r2_score(Y_test, model.predict(X_test))\n",
        "print(r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U5qqemzogG3",
        "outputId": "6447b5a4-1094-42d3-c267-1d0e0d2fa7dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.8562e-04 - mae: 0.0107 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f23801a6480> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0006129652028903365, 0.011742222122848034]\n",
            "[0.02013423 0.02020202 0.05472637] 0.04932735426008968\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "0.2601983992740362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "juR88WIHpJS8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "489a257f-97e3-4008-8f81-155972d97b1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0, 0.013422818791946308, 0.0, 0.0, 0.006711409395973154, 0.006711409395973154, 0.0, 0.0, 0.0, 0.006711409395973154, 0.006711409395973154, 0.020134228187919462, 0.03355704697986577, 0.04697986577181208, 0.013422818791946308, 0.03355704697986577, 0.06711409395973154, 0.053691275167785234, 0.03355704697986577, 0.026845637583892617, 0.020134228187919462, 0.06040268456375839, 0.09395973154362416, 0.0738255033557047, 0.08053691275167785, 0.06711409395973154, 0.053691275167785234, 0.06711409395973154, 0.026845637583892617, 0.04697986577181208, 0.040268456375838924], [0.0, 0.005050505050505051, 0.0, 0.0, 0.0, 0.005050505050505051, 0.025252525252525252, 0.030303030303030304, 0.06060606060606061, 0.020202020202020204, 0.020202020202020204, 0.045454545454545456, 0.050505050505050504, 0.03535353535353535, 0.04040404040404041, 0.045454545454545456, 0.025252525252525252, 0.015151515151515152, 0.04040404040404041, 0.045454545454545456, 0.020202020202020204, 0.03535353535353535, 0.06565656565656566, 0.030303030303030304, 0.0707070707070707, 0.06060606060606061, 0.04040404040404041, 0.045454545454545456, 0.03535353535353535, 0.03535353535353535, 0.050505050505050504], [0.0, 0.004975124378109453, 0.004975124378109453, 0.03482587064676617, 0.029850746268656716, 0.01990049751243781, 0.014925373134328358, 0.009950248756218905, 0.0, 0.009950248756218905, 0.014925373134328358, 0.009950248756218905, 0.029850746268656716, 0.01990049751243781, 0.03482587064676617, 0.03482587064676617, 0.05970149253731343, 0.029850746268656716, 0.03980099502487562, 0.029850746268656716, 0.05472636815920398, 0.029850746268656716, 0.05472636815920398, 0.03482587064676617, 0.04477611940298507, 0.04477611940298507, 0.05472636815920398, 0.04477611940298507, 0.06965174129353234, 0.06965174129353234, 0.06467661691542288], [0.0, 0.0, 0.017937219730941704, 0.004484304932735426, 0.004484304932735426, 0.017937219730941704, 0.004484304932735426, 0.026905829596412557, 0.02242152466367713, 0.03139013452914798, 0.04035874439461883, 0.04932735426008968, 0.03139013452914798, 0.04932735426008968, 0.017937219730941704, 0.04932735426008968, 0.07174887892376682, 0.04484304932735426, 0.026905829596412557, 0.02242152466367713, 0.04932735426008968, 0.026905829596412557, 0.026905829596412557, 0.04035874439461883, 0.04035874439461883, 0.02242152466367713, 0.03139013452914798, 0.05829596412556054, 0.06278026905829596, 0.04932735426008968, 0.05829596412556054], [0.0, 0.008733624454148471, 0.008733624454148471, 0.008733624454148471, 0.013100436681222707, 0.026200873362445413, 0.034934497816593885, 0.048034934497816595, 0.03056768558951965, 0.03056768558951965, 0.008733624454148471, 0.03056768558951965, 0.026200873362445413, 0.034934497816593885, 0.026200873362445413, 0.034934497816593885, 0.05240174672489083, 0.039301310043668124, 0.026200873362445413, 0.03056768558951965, 0.034934497816593885, 0.056768558951965066, 0.0611353711790393, 0.004366812227074236, 0.048034934497816595, 0.043668122270742356, 0.05240174672489083, 0.026200873362445413, 0.03056768558951965, 0.043668122270742356, 0.07860262008733625], [0.004329004329004329, 0.004329004329004329, 0.004329004329004329, 0.008658008658008658, 0.004329004329004329, 0.004329004329004329, 0.008658008658008658, 0.021645021645021644, 0.008658008658008658, 0.012987012987012988, 0.025974025974025976, 0.03896103896103896, 0.021645021645021644, 0.03463203463203463, 0.03463203463203463, 0.04329004329004329, 0.04329004329004329, 0.04329004329004329, 0.03896103896103896, 0.03896103896103896, 0.021645021645021644, 0.06060606060606061, 0.05194805194805195, 0.04329004329004329, 0.05627705627705628, 0.06926406926406926, 0.04329004329004329, 0.047619047619047616, 0.05627705627705628, 0.05627705627705628, 0.047619047619047616], [0.005076142131979695, 0.0, 0.005076142131979695, 0.005076142131979695, 0.015228426395939087, 0.015228426395939087, 0.015228426395939087, 0.04060913705583756, 0.025380710659898477, 0.02030456852791878, 0.015228426395939087, 0.03553299492385787, 0.02030456852791878, 0.05583756345177665, 0.050761421319796954, 0.04568527918781726, 0.04568527918781726, 0.03553299492385787, 0.06091370558375635, 0.030456852791878174, 0.050761421319796954, 0.02030456852791878, 0.05583756345177665, 0.04568527918781726, 0.015228426395939087, 0.050761421319796954, 0.030456852791878174, 0.06091370558375635, 0.06091370558375635, 0.01015228426395939, 0.05583756345177665], [0.0, 0.007380073800738007, 0.0036900369003690036, 0.01845018450184502, 0.014760147601476014, 0.0036900369003690036, 0.007380073800738007, 0.014760147601476014, 0.0036900369003690036, 0.01107011070110701, 0.01107011070110701, 0.007380073800738007, 0.01107011070110701, 0.033210332103321034, 0.02214022140221402, 0.033210332103321034, 0.01845018450184502, 0.014760147601476014, 0.007380073800738007, 0.04428044280442804, 0.05166051660516605, 0.02952029520295203, 0.06273062730627306, 0.04059040590405904, 0.02952029520295203, 0.06273062730627306, 0.033210332103321034, 0.04428044280442804, 0.07011070110701106, 0.23247232472324722, 0.055350553505535055], [0.0, 0.004329004329004329, 0.0, 0.004329004329004329, 0.004329004329004329, 0.008658008658008658, 0.025974025974025976, 0.008658008658008658, 0.012987012987012988, 0.021645021645021644, 0.03463203463203463, 0.025974025974025976, 0.03463203463203463, 0.05194805194805195, 0.021645021645021644, 0.017316017316017316, 0.05194805194805195, 0.03463203463203463, 0.06060606060606061, 0.025974025974025976, 0.021645021645021644, 0.017316017316017316, 0.030303030303030304, 0.047619047619047616, 0.047619047619047616, 0.03896103896103896, 0.03896103896103896, 0.04329004329004329, 0.05627705627705628, 0.16017316017316016, 0.047619047619047616], [0.0, 0.0, 0.00851063829787234, 0.00851063829787234, 0.00851063829787234, 0.01702127659574468, 0.01702127659574468, 0.01702127659574468, 0.03404255319148936, 0.02127659574468085, 0.02553191489361702, 0.00425531914893617, 0.00425531914893617, 0.04680851063829787, 0.03404255319148936, 0.0425531914893617, 0.02127659574468085, 0.02553191489361702, 0.0425531914893617, 0.029787234042553193, 0.03829787234042553, 0.04680851063829787, 0.059574468085106386, 0.059574468085106386, 0.04680851063829787, 0.04680851063829787, 0.03829787234042553, 0.05106382978723404, 0.03404255319148936, 0.11914893617021277, 0.05106382978723404], [0.0, 0.007352941176470588, 0.003676470588235294, 0.003676470588235294, 0.011029411764705883, 0.022058823529411766, 0.011029411764705883, 0.01838235294117647, 0.007352941176470588, 0.011029411764705883, 0.011029411764705883, 0.03308823529411765, 0.025735294117647058, 0.0625, 0.03676470588235294, 0.03308823529411765, 0.022058823529411766, 0.27205882352941174, 0.022058823529411766, 0.022058823529411766, 0.04044117647058824, 0.03308823529411765, 0.029411764705882353, 0.022058823529411766, 0.03676470588235294, 0.04411764705882353, 0.03676470588235294, 0.022058823529411766, 0.014705882352941176, 0.05514705882352941, 0.029411764705882353], [0.008032128514056224, 0.0, 0.0, 0.01606425702811245, 0.008032128514056224, 0.0, 0.012048192771084338, 0.012048192771084338, 0.024096385542168676, 0.012048192771084338, 0.0321285140562249, 0.020080321285140562, 0.024096385542168676, 0.028112449799196786, 0.028112449799196786, 0.01606425702811245, 0.028112449799196786, 0.012048192771084338, 0.028112449799196786, 0.028112449799196786, 0.04417670682730924, 0.040160642570281124, 0.028112449799196786, 0.0321285140562249, 0.04819277108433735, 0.060240963855421686, 0.06827309236947791, 0.04417670682730924, 0.05220883534136546, 0.060240963855421686, 0.18473895582329317], [0.004878048780487805, 0.00975609756097561, 0.014634146341463415, 0.004878048780487805, 0.004878048780487805, 0.014634146341463415, 0.014634146341463415, 0.014634146341463415, 0.00975609756097561, 0.014634146341463415, 0.024390243902439025, 0.03902439024390244, 0.024390243902439025, 0.024390243902439025, 0.03902439024390244, 0.024390243902439025, 0.04878048780487805, 0.05365853658536585, 0.04878048780487805, 0.04390243902439024, 0.04390243902439024, 0.03902439024390244, 0.03414634146341464, 0.04878048780487805, 0.05365853658536585, 0.04390243902439024, 0.04878048780487805, 0.06341463414634146, 0.05365853658536585, 0.01951219512195122, 0.07317073170731707], [0.004524886877828055, 0.00904977375565611, 0.00904977375565611, 0.03619909502262444, 0.04072398190045249, 0.0, 0.027149321266968326, 0.00904977375565611, 0.03619909502262444, 0.03619909502262444, 0.04072398190045249, 0.04072398190045249, 0.02262443438914027, 0.02262443438914027, 0.01809954751131222, 0.03167420814479638, 0.04072398190045249, 0.03619909502262444, 0.013574660633484163, 0.03167420814479638, 0.01809954751131222, 0.03167420814479638, 0.05429864253393665, 0.03619909502262444, 0.027149321266968326, 0.049773755656108594, 0.04524886877828054, 0.03619909502262444, 0.049773755656108594, 0.07239819004524888, 0.07239819004524888], [0.0, 0.005780346820809248, 0.0, 0.017341040462427744, 0.023121387283236993, 0.017341040462427744, 0.011560693641618497, 0.011560693641618497, 0.028901734104046242, 0.005780346820809248, 0.011560693641618497, 0.028901734104046242, 0.023121387283236993, 0.017341040462427744, 0.03468208092485549, 0.07514450867052024, 0.04046242774566474, 0.028901734104046242, 0.03468208092485549, 0.046242774566473986, 0.03468208092485549, 0.028901734104046242, 0.08092485549132948, 0.04046242774566474, 0.03468208092485549, 0.04046242774566474, 0.06936416184971098, 0.057803468208092484, 0.05202312138728324, 0.028901734104046242, 0.06936416184971098], [0.0, 0.010810810810810811, 0.010810810810810811, 0.010810810810810811, 0.016216216216216217, 0.016216216216216217, 0.03783783783783784, 0.005405405405405406, 0.02702702702702703, 0.043243243243243246, 0.032432432432432434, 0.032432432432432434, 0.043243243243243246, 0.02702702702702703, 0.010810810810810811, 0.005405405405405406, 0.04864864864864865, 0.02702702702702703, 0.05405405405405406, 0.03783783783783784, 0.03783783783783784, 0.043243243243243246, 0.03783783783783784, 0.03783783783783784, 0.07567567567567568, 0.03783783783783784, 0.04864864864864865, 0.043243243243243246, 0.032432432432432434, 0.043243243243243246, 0.06486486486486487], [0.0, 0.0, 0.015873015873015872, 0.010582010582010581, 0.005291005291005291, 0.015873015873015872, 0.015873015873015872, 0.010582010582010581, 0.005291005291005291, 0.021164021164021163, 0.021164021164021163, 0.031746031746031744, 0.010582010582010581, 0.05291005291005291, 0.021164021164021163, 0.042328042328042326, 0.05291005291005291, 0.06349206349206349, 0.0582010582010582, 0.042328042328042326, 0.037037037037037035, 0.037037037037037035, 0.031746031746031744, 0.042328042328042326, 0.08465608465608465, 0.06878306878306878, 0.042328042328042326, 0.031746031746031744, 0.042328042328042326, 0.0582010582010582, 0.026455026455026454], [0.0, 0.005494505494505495, 0.01098901098901099, 0.01098901098901099, 0.016483516483516484, 0.01098901098901099, 0.016483516483516484, 0.02197802197802198, 0.04395604395604396, 0.016483516483516484, 0.04945054945054945, 0.02197802197802198, 0.03296703296703297, 0.03296703296703297, 0.005494505494505495, 0.027472527472527472, 0.02197802197802198, 0.02197802197802198, 0.01098901098901099, 0.038461538461538464, 0.03296703296703297, 0.06043956043956044, 0.04945054945054945, 0.03296703296703297, 0.07692307692307693, 0.08241758241758242, 0.038461538461538464, 0.03296703296703297, 0.07142857142857142, 0.054945054945054944, 0.04945054945054945]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "91Ay0E0u2wHZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}